# Test Project TrÃªn Local

## ğŸš€ Quick Start

### Option 1: DÃ¹ng Script Tá»± Äá»™ng (KhuyÃªn dÃ¹ng)

```bash
./test-local.sh
```

Script sáº½ tá»± Ä‘á»™ng:
1. Build Docker images
2. Start API service
3. Test crawler (first page only)
4. Test API endpoints

### Option 2: Manual Steps

#### 1. Táº¡o .env

```bash
cp .env.local .env
# Hoáº·c táº¡o thá»§ cÃ´ng vá»›i thÃ´ng tin MySQL cá»§a báº¡n
```

#### 2. Import Database Schema

**Náº¿u dÃ¹ng MySQL local:**
```bash
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 < database_schema_complete.sql
```

**Náº¿u chÆ°a cÃ³ MySQL local**, cÃ³ thá»ƒ dÃ¹ng MySQL container:
```bash
# Uncomment section db trong docker-compose.yml
# Sau Ä‘Ã³:
docker compose up -d db
# Äá»£i MySQL khá»Ÿi Ä‘á»™ng (30 giÃ¢y)
# Import schema vÃ o container
docker compose exec db mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 < database_schema_complete.sql
```

#### 3. Build Images

```bash
docker compose build
```

#### 4. Start API

```bash
docker compose up -d api
```

#### 5. Test Crawler

```bash
# Test vá»›i first page only
docker compose run --rm crawler --first-page-only

# Hoáº·c test vá»›i date cá»¥ thá»ƒ
docker compose run --rm crawler --date 2026-01-26 --first-page-only
```

#### 6. Test API

```bash
# Health check
curl http://localhost:8000/health

# Fetch logs
curl http://localhost:8000/api/fetch-logs

# Aggregated metrics
curl http://localhost:8000/api/aggregated-metrics

# Raw data
curl http://localhost:8000/api/raw-data?limit=5
```

## ğŸ“Š Verify Flow

### 1. Crawler cháº¡y â†’ LÆ°u data
```bash
docker compose run --rm crawler --first-page-only
```

Kiá»ƒm tra:
```bash
# Xem fetch logs
curl http://localhost:8000/api/fetch-logs

# Xem raw data
curl http://localhost:8000/api/raw-data
```

### 2. Formulas Ä‘Æ°á»£c tÃ­nh tá»± Ä‘á»™ng
```bash
# Xem computed metrics
curl http://localhost:8000/api/computed-metrics

# Xem aggregated metrics
curl http://localhost:8000/api/aggregated-metrics?metric_name=rpm_total_net_revenue
```

### 3. API tráº£ vá» metrics
```bash
# Láº¥y RPM Total Net Revenue
curl http://localhost:8000/api/aggregated-metrics?metric_name=rpm_total_net_revenue

# Láº¥y RPM per 1000 Players
curl http://localhost:8000/api/computed-metrics?metric_name=rpm_per_1000_players
```

## ğŸ” Debug

### Xem logs:
```bash
# API logs
docker compose logs api

# Crawler logs (last run)
docker compose logs crawler

# Follow logs
docker compose logs -f api
```

### Test database connection:
```bash
docker compose run --rm crawler python -c "from crawler.db import engine; engine.connect(); print('âœ… DB connected')"
```

### Check database:
```bash
# Náº¿u dÃ¹ng MySQL local
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 -e "SELECT COUNT(*) FROM raw_revenue_data;"
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 -e "SELECT COUNT(*) FROM aggregated_metrics;"
```

## âš ï¸ LÆ°u Ã

### MySQL Connection

Náº¿u containers khÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Ä‘áº¿n MySQL local:

**Option 1**: DÃ¹ng `network_mode: host` trong docker-compose.yml:
```yaml
services:
  crawler:
    network_mode: host
  api:
    network_mode: host
```

**Option 2**: DÃ¹ng `host.docker.internal` (macOS/Windows):
```env
DB_HOST=host.docker.internal
```

**Option 3**: DÃ¹ng MySQL container (uncomment trong docker-compose.yml)

## âœ… Checklist Test

- [ ] API service cháº¡y Ä‘Æ°á»£c
- [ ] Crawler fetch Ä‘Æ°á»£c data
- [ ] Data Ä‘Æ°á»£c lÆ°u vÃ o database
- [ ] Formulas Ä‘Æ°á»£c tÃ­nh tá»± Ä‘á»™ng
- [ ] API tráº£ vá» metrics Ä‘Ãºng
- [ ] Fetch logs Ä‘Æ°á»£c ghi láº¡i

## ğŸ¯ Sau Khi Test ThÃ nh CÃ´ng

Náº¿u má»i thá»© hoáº¡t Ä‘á»™ng Ä‘Ãºng:
1. Push images lÃªn VPS (Ä‘Ã£ cÃ³ sáºµn: crawler-image.tar, api-image.tar)
2. Follow `DEPLOY_TO_VPS.md` Ä‘á»ƒ deploy
