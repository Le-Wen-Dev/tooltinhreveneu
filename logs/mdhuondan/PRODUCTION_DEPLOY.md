# Production Deployment Guide

## âœ… ÄÃ£ Setup Docker

### Cáº¥u trÃºc:
- `crawler/` - Crawler service (cháº¡y xong exit)
- `api/` - FastAPI service (cháº¡y liÃªn tá»¥c)
- `docker-compose.yml` - Orchestration
- `.env` - Configuration

## ğŸš€ Deploy trÃªn VPS

### 1. Upload code lÃªn server

```bash
# Tá»« mÃ¡y local
scp -P 2222 -r toolgetdata tooltinhreveneu@gmail.com@36.50.27.158:/srv/
```

### 2. SSH vÃ o server

```bash
ssh tooltinhreveneu@gmail.com@36.50.27.158 -p 2222
cd /srv/toolgetdata
```

### 3. Táº¡o .env

```bash
cp .env.example .env
nano .env
```

Sá»­a:
```env
DB_HOST=localhost  # VÃ¬ MySQL trÃªn cÃ¹ng server
DB_PORT=3306
DB_NAME=tooltinhreveneu_1
DB_USER=tooltinhreveneu_1
DB_PASSWORD=tooltinhreveneu@gndhsggkl
```

### 4. Import database schema

```bash
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 < database_schema_complete.sql
```

### 5. Build Docker images

```bash
docker compose build
```

### 6. Start API service

```bash
docker compose up -d api
```

### 7. Test crawler

```bash
docker compose run --rm crawler --first-page-only
```

### 8. Setup Cron

```bash
crontab -e
```

ThÃªm:
```bash
# Cháº¡y crawler 2 láº§n má»—i ngÃ y: 1:00 AM vÃ  1:00 PM
0 1,13 * * * cd /srv/toolgetdata && /srv/toolgetdata/run-crawler.sh
```

Hoáº·c dÃ¹ng script wrapper:
```bash
0 1,13 * * * /srv/toolgetdata/run-crawler.sh
```

## ğŸ“Š Verify

### Check API:
```bash
curl http://localhost:8000/health
curl http://localhost:8000/api/aggregated-metrics
```

### Check logs:
```bash
tail -f /var/log/revenue-crawler.log
docker compose logs api
```

### Check database:
```bash
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 -e "SELECT COUNT(*) FROM raw_revenue_data;"
```

## ğŸ”„ Update

```bash
cd /srv/toolgetdata
git pull  # Náº¿u dÃ¹ng git
docker compose build
docker compose up -d --force-recreate api
```

## ğŸ”’ Security Checklist

- [x] MySQL khÃ´ng expose public (localhost only)
- [x] DB user riÃªng (khÃ´ng pháº£i root)
- [x] Lock mechanism (crawl_runs table)
- [x] Logs ra file
- [ ] API cÃ³ authentication (náº¿u cáº§n)
- [ ] Reverse proxy vá»›i SSL (nginx)

## ğŸ“ Notes

- **Crawler**: Cháº¡y xong exit, khÃ´ng restart
- **API**: Cháº¡y liÃªn tá»¥c, auto restart
- **Cron**: Trigger crawler 2 láº§n/ngÃ y
- **DB**: DÃ¹ng MySQL server cÃ³ sáºµn (khÃ´ng dÃ¹ng container)
