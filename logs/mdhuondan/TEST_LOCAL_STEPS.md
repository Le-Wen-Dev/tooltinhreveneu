# Test Project TrÃªn Local - Tá»«ng BÆ°á»›c

## ðŸŽ¯ Option 1: DÃ¹ng MySQL Container (Dá»… nháº¥t)

### BÆ°á»›c 1: Start MySQL Container
```bash
docker compose -f docker-compose.local.yml up -d db
```

Äá»£i 30 giÃ¢y Ä‘á»ƒ MySQL khá»Ÿi Ä‘á»™ng vÃ  import schema tá»± Ä‘á»™ng.

### BÆ°á»›c 2: Verify MySQL
```bash
docker compose -f docker-compose.local.yml exec db mysql -u tooltinhreveneu_1 -ptooltinhreveneu@gndhsggkl tooltinhreveneu_1 -e "SHOW TABLES;"
```

Káº¿t quáº£ mong Ä‘á»£i: 7 tables (raw_revenue_data, formulas, computed_metrics, aggregated_metrics, fetch_logs, admin_users, crawl_runs)

### BÆ°á»›c 3: Setup .env
```bash
cat > .env << EOF
DB_TYPE=mysql
DB_HOST=db
DB_PORT=3306
DB_NAME=tooltinhreveneu_1
DB_USER=tooltinhreveneu_1
DB_PASSWORD=tooltinhreveneu@gndhsggkl
SCRAPER_USERNAME=maxvaluemedia
SCRAPER_PASSWORD=gliacloud
API_PORT=8000
EOF
```

### BÆ°á»›c 4: Build vÃ  Start API
```bash
docker compose -f docker-compose.local.yml build api
docker compose -f docker-compose.local.yml up -d api
```

### BÆ°á»›c 5: Test API
```bash
# Äá»£i 10 giÃ¢y
sleep 10

# Health check
curl http://localhost:8000/health

# Swagger UI
open http://localhost:8000/docs
```

### BÆ°á»›c 6: Test Crawler
```bash
docker compose -f docker-compose.local.yml run --rm crawler --first-page-only
```

### BÆ°á»›c 7: Verify Data
```bash
# Fetch logs
curl http://localhost:8000/api/fetch-logs | python3 -m json.tool

# Raw data
curl http://localhost:8000/api/raw-data | python3 -m json.tool

# Aggregated metrics
curl http://localhost:8000/api/aggregated-metrics | python3 -m json.tool
```

## ðŸŽ¯ Option 2: DÃ¹ng MySQL Local (Náº¿u Ä‘Ã£ cÃ³ MySQL)

### BÆ°á»›c 1: Import Schema
```bash
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 < database_schema_complete.sql
```

### BÆ°á»›c 2: Setup .env
```bash
cat > .env << EOF
DB_TYPE=mysql
DB_HOST=host.docker.internal  # macOS/Windows
# Hoáº·c DB_HOST=172.17.0.1  # Linux
DB_PORT=3306
DB_NAME=tooltinhreveneu_1
DB_USER=tooltinhreveneu_1
DB_PASSWORD=tooltinhreveneu@gndhsggkl
SCRAPER_USERNAME=maxvaluemedia
SCRAPER_PASSWORD=gliacloud
API_PORT=8000
EOF
```

### BÆ°á»›c 3: Build vÃ  Start
```bash
docker compose build
docker compose up -d api
```

### BÆ°á»›c 4: Test
```bash
# Test crawler
docker compose run --rm crawler --first-page-only

# Test API
curl http://localhost:8000/health
```

## ðŸ” Debug

### Xem logs:
```bash
# API
docker compose -f docker-compose.local.yml logs api

# Crawler
docker compose -f docker-compose.local.yml logs crawler

# MySQL
docker compose -f docker-compose.local.yml logs db
```

### Test database connection:
```bash
docker compose -f docker-compose.local.yml exec api python -c "from crawler.db import engine; engine.connect(); print('âœ… Connected')"
```

### Check data:
```bash
docker compose -f docker-compose.local.yml exec db mysql -u tooltinhreveneu_1 -ptooltinhreveneu@gndhsggkl tooltinhreveneu_1 -e "SELECT COUNT(*) FROM raw_revenue_data;"
```

## âœ… Flow Test Checklist

1. [ ] MySQL container cháº¡y Ä‘Æ°á»£c
2. [ ] Schema Ä‘Ã£ Ä‘Æ°á»£c import
3. [ ] API service cháº¡y Ä‘Æ°á»£c
4. [ ] Crawler fetch Ä‘Æ°á»£c data
5. [ ] Data Ä‘Æ°á»£c lÆ°u vÃ o database
6. [ ] Formulas Ä‘Æ°á»£c tÃ­nh tá»± Ä‘á»™ng
7. [ ] API tráº£ vá» metrics Ä‘Ãºng

## ðŸ›‘ Stop Services

```bash
# Stop táº¥t cáº£
docker compose -f docker-compose.local.yml down

# Stop vÃ  xÃ³a database volume (reset)
docker compose -f docker-compose.local.yml down -v
```

## ðŸš€ Sau Khi Test ThÃ nh CÃ´ng

Náº¿u má»i thá»© hoáº¡t Ä‘á»™ng Ä‘Ãºng:
1. âœ… Push images lÃªn VPS (Ä‘Ã£ cÃ³: crawler-image.tar, api-image.tar)
2. âœ… Follow `DEPLOY_TO_VPS.md` Ä‘á»ƒ deploy production
