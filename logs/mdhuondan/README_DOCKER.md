# Docker Setup - Quick Start

## âœ… ÄÃ£ Setup

### Cáº¥u trÃºc:
```
â”œâ”€â”€ crawler/          # Crawler service (cháº¡y xong exit)
â”œâ”€â”€ api/              # FastAPI service (cháº¡y liÃªn tá»¥c)
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env
```

### Luá»“ng hoáº¡t Ä‘á»™ng:
1. **Crawler** â†’ Fetch data â†’ LÆ°u DB â†’ TÃ­nh formulas â†’ Exit
2. **API** â†’ Query metrics â†’ Tráº£ JSON
3. **Cron** â†’ Trigger crawler 2 láº§n/ngÃ y

## ğŸš€ Quick Start

### 1. Setup .env
```bash
cp .env.example .env
# Sá»­a DB_HOST=db (hoáº·c localhost náº¿u dÃ¹ng DB ngoÃ i)
```

### 2. Cháº¡y services
```bash
# Start API + DB
docker compose up -d api db

# Test crawler
docker compose run --rm crawler --first-page-only
```

### 3. Setup Cron (VPS)
```bash
crontab -e

# ThÃªm:
0 1,13 * * * cd /srv/revenue-crawler && docker compose run --rm crawler >> /var/log/revenue-crawler.log 2>&1
```

## ğŸ“Š API Endpoints

```bash
# Health check
curl http://localhost:8000/health

# Get metrics
curl http://localhost:8000/api/aggregated-metrics?metric_name=rpm_total_net_revenue

# Get fetch logs
curl http://localhost:8000/api/fetch-logs
```

## ğŸ”’ Báº£o Máº­t

- âœ… MySQL khÃ´ng expose public (bá» port mapping)
- âœ… DB user riÃªng cho crawler
- âœ… Lock mechanism (crawl_runs table)
- âœ… Logs ra file

Xem chi tiáº¿t: `DOCKER_SETUP.md`
