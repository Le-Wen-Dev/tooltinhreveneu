# Quick Deploy Guide - TÃ³m Táº¯t Nhanh

## âœ… ÄÃ£ HoÃ n ThÃ nh

### Docker Images:
- âœ… `toolgetdata-crawler:latest` (137MB)
- âœ… `toolgetdata-api:latest` (141MB)
- âœ… ÄÃ£ save thÃ nh: `crawler-image.tar` vÃ  `api-image.tar`

## ğŸš€ Deploy LÃªn VPS (3 BÆ°á»›c)

### 1. Upload Images
```bash
scp -P 2222 crawler-image.tar api-image.tar docker-compose.yml database_schema_complete.sql tooltinhreveneu@gmail.com@36.50.27.158:/srv/toolgetdata/
```

### 2. SSH vÃ  Setup
```bash
ssh tooltinhreveneu@gmail.com@36.50.27.158 -p 2222
cd /srv/toolgetdata

# Load images
docker load -i crawler-image.tar
docker load -i api-image.tar

# Import database (1 láº§n duy nháº¥t)
mysql -u tooltinhreveneu_1 -p tooltinhreveneu_1 < database_schema_complete.sql

# Táº¡o .env
cat > .env << EOF
DB_TYPE=mysql
DB_HOST=localhost
DB_PORT=3306
DB_NAME=tooltinhreveneu_1
DB_USER=tooltinhreveneu_1
DB_PASSWORD=tooltinhreveneu@gndhsggkl
SCRAPER_USERNAME=maxvaluemedia
SCRAPER_PASSWORD=gliacloud
API_PORT=8000
EOF

# Start API
docker compose up -d api

# Test crawler
docker compose run --rm crawler --first-page-only
```

### 3. Setup Cron
```bash
crontab -e
# ThÃªm:
0 1,13 * * * cd /srv/toolgetdata && docker compose run --rm crawler >> /var/log/revenue-crawler.log 2>&1
```

## â“ Vá» MySQL

**KHÃ”NG Cáº¦N** setup MySQL gÃ¬ thÃªm vÃ¬:
- âœ… MySQL Ä‘Ã£ cÃ³ sáºµn trÃªn VPS
- âœ… Database `tooltinhreveneu_1` Ä‘Ã£ tá»“n táº¡i
- âœ… Chá»‰ cáº§n import schema 1 láº§n: `database_schema_complete.sql`

## ğŸ“ Files Cáº§n Upload

1. `crawler-image.tar` - Crawler image
2. `api-image.tar` - API image
3. `docker-compose.yml` - Docker config
4. `database_schema_complete.sql` - Database schema

## âœ… Sau Khi Deploy

- API: `http://36.50.27.158:8000`
- Health: `curl http://36.50.27.158:8000/health`
- Metrics: `curl http://36.50.27.158:8000/api/aggregated-metrics`

Xem chi tiáº¿t: `DEPLOY_TO_VPS.md`
